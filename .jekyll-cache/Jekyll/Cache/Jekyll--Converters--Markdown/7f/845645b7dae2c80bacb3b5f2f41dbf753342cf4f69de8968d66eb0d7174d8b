I"<ul>
  <li>Different from typical MI attacks utilizing shadow models to simulate the target model, our attack framework probes the target model and extracts membership semantics via differential comparison.</li>
  <li>The high-level idea is that BLINDMI first generates a dataset with nonmembers via transforming existing samples into new, 
and then differentially moves samples from a target dataset to the generated, non-member set in an iterative manner.</li>
  <li>Our method outperforms all SOTA MI attacks and remain</li>
</ul>
:ET